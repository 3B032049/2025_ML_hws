{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFEPtvPZeDqxd5PWKNooJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3B032049/2025_ML_hws/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "oEtYuxY5wwJb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 激活函數"
      ],
      "metadata": {
        "id": "hUiTuMTJwxiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "def cross_entropy_error(y_hat, y):\n",
        "    return -np.sum(y * np.log(y_hat + 1e-7)) / len(y)\n",
        "\n",
        "def dnn(x):\n",
        "    # 第一層\n",
        "    z1 = np.dot(x, W1) + b1\n",
        "    h1 = relu(z1)\n",
        "\n",
        "    # 第二層\n",
        "    z2 = np.dot(h1, W2) + b2\n",
        "    h2 = relu(z2)\n",
        "\n",
        "    # 第三層\n",
        "    z3 = np.dot(h2, W3) + b3\n",
        "    h3 = sigmoid(z3)\n",
        "\n",
        "    # 輸出層\n",
        "    z4 = np.dot(h3, W4) + b4\n",
        "    y_hat = softmax(z4)\n",
        "    return y_hat\n"
      ],
      "metadata": {
        "id": "FPBQGu6jw-Zj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 定義神經網路結構"
      ],
      "metadata": {
        "id": "K0OhJ_nfxAtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "# 每筆6個神經元 所以共5*6=30\n",
        "X=np.array([[10.0, 8.0, -6.0, 4.0, -2.0, 0.0],\n",
        "    [-16.0, 4.0, -10.0, 8.0, 10.0, 12.0],\n",
        "    [1.0, 3.0, -9.0, 7.0, 9.0, 11.0],\n",
        "    [8.0, 6.0, 4.0, -4.0, 4.0, -6.0],\n",
        "    [2.0, -3.0, 4.0, 5.0, -6.0, 7.0]])\n",
        "\n",
        "# 真實結果\n",
        "Y=np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]])"
      ],
      "metadata": {
        "id": "dxK6ebh8xF5L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 初始化權重和偏值"
      ],
      "metadata": {
        "id": "xxgjBHF8xHlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.array([[0.1, -0.2, 0.3, -0.4, 0.5],\n",
        "               [-0.5, 0.4, -0.3, 0.2, -0.1],\n",
        "               [0.2, -0.3, 0.4, -0.5, 0.6],\n",
        "               [-0.6, 0.5, -0.4, 0.3, -0.2],\n",
        "               [0.7, -0.8, 0.9, -1.0, 1.1],\n",
        "               [-0.1, 0.2, -0.3, 0.4, -0.5]])\n",
        "b1 = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
        "\n",
        "W2 = np.array([[0.1, -0.1, 0.2, -0.2],\n",
        "               [-0.3, 0.4, -0.5, 0.6],\n",
        "               [0.7, -0.8, 0.9, -1.0],\n",
        "               [0.1, -0.2, 0.3, -0.4],\n",
        "               [-0.5, 0.6, -0.7, 0.8]])\n",
        "b2 = np.array([0.1, 0.2, 0.3, 0.4])\n",
        "\n",
        "W3 = np.array([[0.1, -0.2, 0.3, -0.4],\n",
        "               [-0.5, 0.6, -0.7, 0.8],\n",
        "               [0.9, -1.0, 1.1, -1.2],\n",
        "               [-0.3, 0.4, -0.5, 0.6]])\n",
        "b3 = np.array([0.1, 0.2, 0.3, 0.4])\n",
        "\n",
        "W4 = np.array([[0.1, -0.2, 0.3],\n",
        "               [-0.4, 0.5, -0.6],\n",
        "               [0.7, -0.8, 0.9],\n",
        "               [-1.0, 1.1, -1.2]])\n",
        "b4 = np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "def batch_predict(X, Y):\n",
        "    # 預測 Y_hat\n",
        "    Y_hat = dnn(X)\n",
        "    # 計算交叉熵誤差\n",
        "    loss = cross_entropy_error(Y_hat, Y)\n",
        "    return Y_hat, loss\n",
        "\n",
        "print(batch_predict(X, Y))"
      ],
      "metadata": {
        "id": "Da89ytavxLHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13700ab0-2cb3-45e7-8aff-e437fd066119"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[0.05285634, 0.90109443, 0.04604923],\n",
            "       [0.14338375, 0.70224135, 0.1543749 ],\n",
            "       [0.12748825, 0.7387379 , 0.13377385],\n",
            "       [0.09057184, 0.82099406, 0.08843411],\n",
            "       [0.0904733 , 0.82131194, 0.08821476]]), np.float64(2.0302559795298416))\n"
          ]
        }
      ]
    }
  ]
}